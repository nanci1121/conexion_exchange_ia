services:
  # Base de datos para RAG (PostgreSQL con extensión pgvector)
  postgres_vectordb:
    image: ankane/pgvector:latest
    container_name: email_ai_postgres
    environment:
      POSTGRES_USER: ${DB_USER:-email_ai_user}
      POSTGRES_PASSWORD: ${DB_PASS:-super_secreto}
      POSTGRES_DB: knowledge_base
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    restart: unless-stopped

  # API del Modelo LLM (FastAPI cargando TinyLlama con adaptador en 4-bit)
  llm_service:
    build:
      context: ./llm_service
      dockerfile: Dockerfile
    container_name: email_ai_llm
    environment:
      - PYTHONUNBUFFERED=1
      - CPU_THREADS=4
    volumes:
      # Montamos la carpeta del modelo final; asegúrate de que exista la ruta
      - ./modelo_correos_final:/app/modelo_correos_final
      - hf_cache:/root/.cache/huggingface
      # Montar app.py para poder editar sin rebuild
      - ./llm_service/app.py:/app/app.py
    ports:
      - "8000:8000"
    # Descomenta las siguientes líneas si tienes NVIDIA Container Toolkit instalado en WSL
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia # Para usar la GPU en WSL (CUDA)
    #           count: 1
    #           capabilities: [ gpu ]
    restart: unless-stopped

  # Aplicación Principal (lógica de Exchange, RAG)
  email_app:
    build:
      context: ./
      dockerfile: Dockerfile
    container_name: email_ai_app
    ports:
      - "8080:8080"
    environment:
      - PYTHONUNBUFFERED=1
      - DB_HOST=postgres_vectordb
      - DB_PORT=5432
      - DB_USER=${DB_USER:-email_ai_user}
      - DB_PASS=${DB_PASS:-super_secreto}
      - DB_NAME=knowledge_base
      - LLM_API_URL=http://llm_service:8000
    env_file:
      - .env
    depends_on:
      - postgres_vectordb
      - llm_service
    volumes:
      # Monta el código base
      - ./src:/app/src
      # También montamos la carpeta global config/
      - ./config:/app/config
    command: uvicorn src.main:app --host 0.0.0.0 --port 8080
    restart: unless-stopped

volumes:
  pgdata:
  hf_cache:
